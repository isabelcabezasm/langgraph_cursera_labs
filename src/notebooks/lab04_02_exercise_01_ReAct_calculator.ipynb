{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abf8e348",
   "metadata": {},
   "source": [
    "Exercise 1 - Build a Calculator Tool\n",
    "Objective: Create a mathematical calculator tool that can handle complex calculations.\n",
    "\n",
    "Your task is to create a calculator tool that can perform mathematical operations. This tool should be able to handle expressions like \"2 + 3 * 4\", \"sqrt(16)\", and \"sin(π/2)\".\n",
    "\n",
    "Instructions:\n",
    "Create a tool called calculator_tool using the @tool decorator.\n",
    "The tool should accept a mathematical expression as a string.\n",
    "Use Python's eval() function carefully (or better yet, use the ast module for safety).\n",
    "Test your tool with various mathematical expressions.\n",
    "Add your tool to the tools list and test it with the ReAct agent.\n",
    "Starter Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4858a61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, ToolMessage\n",
    "\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "from typing import (Annotated,Sequence,TypedDict)\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain.tools import tool\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b38b7f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import ast\n",
    "import operator\n",
    "\n",
    "@tool\n",
    "def calculator_tool(expression: str) -> str:\n",
    "    \"\"\"\n",
    "    Safely evaluate mathematical expressions.\n",
    "    \n",
    "    :param expression: A mathematical expression as a string (e.g., \"2 + 3 * 4\")\n",
    "    :return: The result of the calculation\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Define safe operators and functions\n",
    "        safe_operators = {\n",
    "            ast.Add: operator.add,\n",
    "            ast.Sub: operator.sub,\n",
    "            ast.Mult: operator.mul,\n",
    "            ast.Div: operator.truediv,\n",
    "            ast.Pow: operator.pow,\n",
    "            ast.USub: operator.neg,\n",
    "            ast.UAdd: operator.pos,\n",
    "        }\n",
    "        \n",
    "        safe_functions = {\n",
    "            'sqrt': math.sqrt,\n",
    "            'sin': math.sin,\n",
    "            'cos': math.cos,\n",
    "            'tan': math.tan,\n",
    "            'log': math.log,\n",
    "            'log10': math.log10,\n",
    "            'exp': math.exp,\n",
    "            'abs': abs,\n",
    "            'pi': math.pi,\n",
    "            'π': math.pi,\n",
    "            'e': math.e,\n",
    "        }\n",
    "        \n",
    "        def safe_eval(node):\n",
    "            if isinstance(node, ast.Constant):\n",
    "                return node.value\n",
    "            elif isinstance(node, ast.BinOp):\n",
    "                left = safe_eval(node.left)\n",
    "                right = safe_eval(node.right)\n",
    "                return safe_operators[type(node.op)](left, right)\n",
    "            elif isinstance(node, ast.UnaryOp):\n",
    "                operand = safe_eval(node.operand)\n",
    "                return safe_operators[type(node.op)](operand)\n",
    "            elif isinstance(node, ast.Call):\n",
    "                func_name = node.func.id\n",
    "                if func_name in safe_functions:\n",
    "                    args = [safe_eval(arg) for arg in node.args]\n",
    "                    return safe_functions[func_name](*args)\n",
    "                else:\n",
    "                    raise ValueError(f\"Function '{func_name}' is not allowed\")\n",
    "            elif isinstance(node, ast.Name):\n",
    "                if node.id in safe_functions:\n",
    "                    return safe_functions[node.id]\n",
    "                else:\n",
    "                    raise ValueError(f\"Variable '{node.id}' is not allowed\")\n",
    "            else:\n",
    "                raise ValueError(f\"Operation not allowed: {type(node)}\")\n",
    "        \n",
    "        # Parse and evaluate the expression\n",
    "        tree = ast.parse(expression, mode='eval')\n",
    "        result = safe_eval(tree.body)\n",
    "        return str(result)\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "    pass\n",
    "\n",
    "# TODO: Add calculator_tool to your tools list\n",
    "# TODO: Test with the agent: \"What's 15% of 250 plus the square root of 144?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e80180fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 + 3 * 4:  14\n",
      "sqrt(16):  4.0\n",
      "sin(π/2):  1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"2 + 3 * 4: \", calculator_tool.invoke(\"2 + 3 * 4\"))  # Example usage\n",
    "print(\"sqrt(16): \", calculator_tool.invoke(\"sqrt(16)\"))  # Example usage\n",
    "print(\"sin(π/2): \", calculator_tool.invoke(\"sin(π/2)\"))  # Example usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "820f42bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools=[calculator_tool]\n",
    "tools_by_name={ tool.name:tool for tool in tools}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "312e03c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure ChatOpenAI for Azure OpenAI\n",
    "deployment_name = \"gpt-4o-mini\"  # Replace with your actual deployment name\n",
    "\n",
    "openai_llm = AzureChatOpenAI(\n",
    "    azure_deployment=deployment_name,\n",
    "    api_version=os.getenv(\"OPENAI_API_VERSION\"),\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    temperature=0.7,\n",
    "    model_name=deployment_name,\n",
    "    max_retries=3,\n",
    "    request_timeout=120,\n",
    "    max_tokens=1024,\n",
    "    top_p=0.95   \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4c0a6ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After greeting: [HumanMessage(content='Hi', additional_kwargs={}, response_metadata={}, id='89e91662-d921-4934-9e2e-da736e1cd1b9')]\n",
      "After question: {'messages': [HumanMessage(content='Hi', additional_kwargs={}, response_metadata={}, id='89e91662-d921-4934-9e2e-da736e1cd1b9'), HumanMessage(content=\"What's 15% of 250 plus the square root of 144?\", additional_kwargs={}, response_metadata={}, id='5ba0beb3-2876-44e9-b630-d3397d1ad8a2')]}\n"
     ]
    }
   ],
   "source": [
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"\n",
    "You are a helpful AI assistant that thinks step-by-step and uses tools when needed.\n",
    "\n",
    "When responding to queries:\n",
    "1. First, think about what information you need\n",
    "2. Use available tools if you need current data or specific capabilities  \n",
    "3. Provide clear, helpful responses based on your reasoning and any tool results\n",
    "\n",
    "IMPORTANT: Use plain text formatting only. Do not use LaTeX, markdown math notation, or special formatting like \\\\[ \\\\] or $$.\n",
    "\n",
    "Always explain your thinking process to help users understand your approach.\n",
    "\"\"\"),\n",
    "    MessagesPlaceholder(variable_name=\"scratch_pad\")\n",
    "])\n",
    "\n",
    "# binding the tools to the LLM\n",
    "model_react = chat_prompt | openai_llm.bind_tools(tools)\n",
    "\n",
    "# Agent state:\n",
    "\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    \"\"\"The state of the agent.\"\"\"\n",
    "    # add_messages is a reducer\n",
    "    # See https://langchain-ai.github.io/langgraph/concepts/low_level/#reducers\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]\n",
    "\n",
    "\n",
    "# Example conversation flow:\n",
    "state: AgentState = {\"messages\": []}\n",
    "\n",
    "# append a message using the reducer properly\n",
    "state[\"messages\"] = add_messages(state[\"messages\"], [HumanMessage(content=\"Hi\")])\n",
    "print(\"After greeting:\", state[\"messages\"])\n",
    "\n",
    "# add another message (e.g. a question)\n",
    "state[\"messages\"] = add_messages(state[\"messages\"], [HumanMessage(content=\"What's 15% of 250 plus the square root of 144?\")])\n",
    "print(\"After question:\", (state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bb39ab90",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query = \"What's 15% of 250 plus the square root of 144?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dd9f6413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial response: content='To solve the expression \"15% of 250 plus the square root of 144\", I will break it down into two parts:\\n\\n1. Calculate 15% of 250.\\n2. Calculate the square root of 144.\\n3. Add the results of these two calculations together.\\n\\nLet\\'s do the calculations step by step. \\n\\nFirst, I\\'ll calculate 15% of 250, which is equivalent to (15/100) * 250. \\n\\nNext, the square root of 144 is 12.\\n\\nFinally, I will add the two results together. \\n\\nI\\'ll perform these calculations now.' additional_kwargs={'tool_calls': [{'id': 'call_fciDc0YLV8v3QI9AQDoorhbn', 'function': {'arguments': '{\"expression\": \"0.15 * 250\"}', 'name': 'calculator_tool'}, 'type': 'function'}, {'id': 'call_nM5IXA51cUDJIHU7Eo6G9XK4', 'function': {'arguments': '{\"expression\": \"sqrt(144)\"}', 'name': 'calculator_tool'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 178, 'prompt_tokens': 196, 'total_tokens': 374, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_efad92c60b', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'tool_calls', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'protected_material_code': {'filtered': False, 'detected': False}, 'protected_material_text': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}} id='run--39dcc8be-308e-4aec-b7e2-ba49641e00e4-0' tool_calls=[{'name': 'calculator_tool', 'args': {'expression': '0.15 * 250'}, 'id': 'call_fciDc0YLV8v3QI9AQDoorhbn', 'type': 'tool_call'}, {'name': 'calculator_tool', 'args': {'expression': 'sqrt(144)'}, 'id': 'call_nM5IXA51cUDJIHU7Eo6G9XK4', 'type': 'tool_call'}] usage_metadata={'input_tokens': 196, 'output_tokens': 178, 'total_tokens': 374}\n",
      "Tool result for calculator_tool: 37.5\n",
      "Tool result for calculator_tool: 12.0\n",
      "================================================================================\n",
      "FINAL RESPONSE:\n",
      "================================================================================\n",
      "I found the results of the calculations:\n",
      "\n",
      "1. 15% of 250 is 37.5.\n",
      "2. The square root of 144 is 12.\n",
      "\n",
      "Now, I will add these two values together:\n",
      "\n",
      "37.5 + 12 = 49.5.\n",
      "\n",
      "Therefore, 15% of 250 plus the square root of 144 is 49.5.\n",
      "\n",
      "================================================================================\n",
      "More tools needed: False\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# 1. initial query processing\n",
    "dummy_state: AgentState = {\n",
    "    \"messages\": [HumanMessage(user_query)]}\n",
    "\n",
    "response = model_react.invoke({\"scratch_pad\":dummy_state[\"messages\"]})\n",
    "dummy_state[\"messages\"]=add_messages(dummy_state[\"messages\"],[response])\n",
    "print(\"Initial response:\", response)\n",
    "\n",
    "# 2. tool execution - handle ALL tool calls\n",
    "if response.tool_calls:\n",
    "    tool_messages = []\n",
    "    for tool_call in response.tool_calls:\n",
    "        tool_result = tools_by_name[tool_call[\"name\"]].invoke(tool_call[\"args\"])\n",
    "        print(f\"Tool result for {tool_call['name']}: {tool_result}\")\n",
    "        \n",
    "        tool_message = ToolMessage(\n",
    "            content=json.dumps(tool_result),\n",
    "            name=tool_call[\"name\"],\n",
    "            tool_call_id=tool_call[\"id\"]\n",
    "        )\n",
    "        tool_messages.append(tool_message)\n",
    "    \n",
    "    # Add all tool messages at once\n",
    "    dummy_state[\"messages\"] = add_messages(dummy_state[\"messages\"], tool_messages)\n",
    "\n",
    "# 3. processing Results and Next Action\n",
    "response = model_react.invoke({\"scratch_pad\": dummy_state[\"messages\"]})\n",
    "dummy_state['messages'] = add_messages(dummy_state['messages'], [response])\n",
    "\n",
    "# 4. Final response generation - properly formatted output\n",
    "print(\"=\" * 80)\n",
    "print(\"FINAL RESPONSE:\")\n",
    "print(\"=\" * 80)\n",
    "if response.content:\n",
    "    # Use repr() to show the raw string, or just print directly for clean output\n",
    "    print(response.content)\n",
    "else:\n",
    "    print(\"No content in response\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(f\"More tools needed: {bool(response.tool_calls)}\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b999c370",
   "metadata": {},
   "source": [
    "this was just for fun, \n",
    "\n",
    "let's do it now with Graphs.\n",
    "\n",
    "first definition of the nodes of the graph:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "91152c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tool execution node\n",
    "def tool_node(state: AgentState):\n",
    "    \"\"\"Execute all tool calls from the last message in the state.\"\"\"\n",
    "    outputs = []\n",
    "    for tool_call in state[\"messages\"][-1].tool_calls:\n",
    "        tool_result = tools_by_name[tool_call[\"name\"]].invoke(tool_call[\"args\"])\n",
    "        outputs.append(\n",
    "            ToolMessage(\n",
    "                content=json.dumps(tool_result),\n",
    "                name=tool_call[\"name\"],\n",
    "                tool_call_id=tool_call[\"id\"],\n",
    "            )\n",
    "        )\n",
    "    return {\"messages\": outputs}\n",
    "\n",
    "\n",
    "# model invocation node\n",
    "def call_model(state: AgentState):\n",
    "    \"\"\"Invoke the model with the current conversation state.\"\"\"\n",
    "    response = model_react.invoke({\"scratch_pad\": state[\"messages\"]})\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "# decision logic node\n",
    "def should_continue(state: AgentState):\n",
    "    \"\"\"Determine whether to continue with tool use or end the conversation.\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    # If there is no function call, then we finish\n",
    "    if not last_message.tool_calls:\n",
    "        return \"end\"\n",
    "    # Otherwise if there is, we continue\n",
    "    else:\n",
    "        return \"continue\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15646ba",
   "metadata": {},
   "source": [
    "then the graph itself:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3615f5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a new graph\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Define the two nodes we will cycle between\n",
    "workflow.add_node(\"agent\", call_model)\n",
    "workflow.add_node(\"tools\", tool_node)\n",
    "\n",
    "# Add edges between nodes\n",
    "workflow.add_edge(\"tools\", \"agent\")  # After tools, always go back to agent\n",
    "\n",
    "# Add conditional logic\n",
    "workflow.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"continue\": \"tools\",  # If tools needed, go to tools node\n",
    "        \"end\": END,          # If done, end the conversation\n",
    "    },\n",
    ")\n",
    "\n",
    "# Set entry point\n",
    "workflow.set_entry_point(\"agent\")\n",
    "\n",
    "# Compile the graph\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be58430",
   "metadata": {},
   "source": [
    "run/test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1e69ebd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What's 15% of 250 plus the square root of 144?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "To solve the expression \"15% of 250 plus the square root of 144,\" I will break it down into two parts:\n",
      "\n",
      "1. Calculate 15% of 250.\n",
      "2. Calculate the square root of 144.\n",
      "3. Add the two results together.\n",
      "\n",
      "First, let's calculate 15% of 250:\n",
      "15% of 250 = 0.15 * 250.\n",
      "\n",
      "Next, the square root of 144 is 12.\n",
      "\n",
      "Now, I will perform the calculations. \n",
      "\n",
      "Let me calculate 15% of 250 and then add the square root of 144.\n",
      "Tool Calls:\n",
      "  calculator_tool (call_6irujZm6ftnMm4X27BpuLjHF)\n",
      " Call ID: call_6irujZm6ftnMm4X27BpuLjHF\n",
      "  Args:\n",
      "    expression: 0.15 * 250\n",
      "  calculator_tool (call_bqHJzO71Zpku5W0fkOPq272k)\n",
      " Call ID: call_bqHJzO71Zpku5W0fkOPq272k\n",
      "  Args:\n",
      "    expression: sqrt(144)\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: calculator_tool\n",
      "\n",
      "\"12.0\"\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I have calculated the two parts:\n",
      "\n",
      "1. 15% of 250 is 37.5.\n",
      "2. The square root of 144 is 12.\n",
      "\n",
      "Now, I will add these two results together:\n",
      "37.5 + 12 = 49.5.\n",
      "\n",
      "Therefore, 15% of 250 plus the square root of 144 equals 49.5.\n"
     ]
    }
   ],
   "source": [
    "def print_stream(stream):\n",
    "    \"\"\"Helper function for formatting the stream nicely.\"\"\"\n",
    "    for s in stream:\n",
    "        message = s[\"messages\"][-1]\n",
    "        if isinstance(message, tuple):\n",
    "            print(message)\n",
    "        else:\n",
    "            message.pretty_print()\n",
    "\n",
    "inputs = {\"messages\": [HumanMessage(content=user_query)]}\n",
    "\n",
    "print_stream(graph.stream(inputs, stream_mode=\"values\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
