# Agent Integration Tests

This directory contains comprehensive integration tests for all agents and components in the docchat application:

- **RelevanceChecker**: Tests document relevance classification
- **ResearchAgent**: Tests answer generation from documents  
- **VerificationAgent**: Tests answer verification against source documents
- **RetrieverBuilder**: Tests hybrid retrieval system (BM25 + vector embeddings)

## Prerequisites

1. **Environment Variables**: Ensure these are set in your `.env` file:
   ```
   AZURE_OPENAI_API_KEY=your_api_key
   AZURE_OPENAI_ENDPOINT=your_endpoint
   AZURE_OPENAI_DEPLOYMENT_NAME=your_deployment
   AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT=your_embedding_deployment
   OPENAI_API_VERSION=your_api_version
   ```

2. **Dependencies**: Install required packages:
   ```bash
   pip install azure-ai-inference azure-core langchain-openai python-dotenv
   ```

## Running Tests

### Run All Tests
```bash
cd /workspaces/cursera_labs/src/lab_05/docchat
python tests/run_tests.py
```

### Run Specific Agent Tests
```bash
# RelevanceChecker only
python tests/run_tests.py relevance

# ResearchAgent only  
python tests/run_tests.py research

# VerificationAgent only
python tests/run_tests.py verification

# RetrieverBuilder only
python tests/run_tests.py builder
```

### Run Individual Test Files
```bash
# Individual test files
python tests/test_relevance_checker.py
python tests/test_research_agent.py
python tests/test_verification_agent.py
python tests/test_retriever_builder.py
```

## Test Coverage

### RelevanceChecker Tests
- âœ… Agent initialization
- âœ… CAN_ANSWER classification
- âœ… PARTIAL classification  
- âœ… NO_MATCH classification
- âœ… Empty retriever handling
- âœ… Different k values
- âœ… Error handling
- âœ… Response validation

### ResearchAgent Tests
- âœ… Agent initialization
- âœ… Prompt generation
- âœ… Response sanitization
- âœ… Answer generation with various document types
- âœ… Empty documents handling
- âœ… Multiple documents processing
- âœ… Error handling
- âœ… Malformed response handling

### VerificationAgent Tests
- âœ… Agent initialization
- âœ… Prompt generation
- âœ… Response sanitization
- âœ… Verification response parsing
- âœ… Report formatting
- âœ… Supported answer verification
- âœ… Unsupported answer detection
- âœ… Contradictory answer detection
- âœ… Empty documents handling
- âœ… Error handling
- âœ… Malformed response handling

### RetrieverBuilder Tests
- âœ… Builder initialization
- âœ… Azure OpenAI embeddings configuration
- âœ… Hybrid retriever creation (BM25 + vector)
- âœ… Single and multiple document handling
- âœ… Retrieval functionality testing
- âœ… Query variation handling
- âœ… K parameter configuration
- âœ… Retriever weight configuration
- âœ… Empty documents error handling
- âœ… Invalid documents error handling
- âœ… Embedding error handling
- âœ… Chroma persistence testing
- âœ… Performance testing

## Test Data

The tests use realistic sample documents covering:
- Azure OpenAI Service documentation
- Text embedding model information
- Machine learning concepts
- Python programming language

This ensures comprehensive testing across different domains and content types.

## Expected Output

When all tests pass, you should see:
```
ðŸŽ‰ ALL AGENT TESTS PASSED! ðŸŽ‰
Your Azure OpenAI agent integration is working correctly!
```

If tests fail, detailed error information will be provided to help debug issues.

## Troubleshooting

1. **Import Errors**: Ensure you're running from the correct directory and all dependencies are installed
2. **API Errors**: Verify your Azure OpenAI credentials and endpoint are correct
3. **Rate Limiting**: Azure OpenAI may rate limit requests; re-run tests if needed
4. **Network Issues**: Ensure you have internet connectivity to reach Azure OpenAI services